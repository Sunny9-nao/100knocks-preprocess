# Pandas ãƒ‡ãƒ¼ã‚¿åˆ†æ å®Œå…¨å…¬å¼é›†ï¼ˆP-001ï½P-100ï¼‰

> ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹100æœ¬ãƒãƒƒã‚¯å®Œå…¨å¯¾å¿œç‰ˆ  
> å„ãƒ†ãƒ¼ãƒã”ã¨ã«å®Ÿè·µçš„ãªæŠ€è¡“ã¨è€ƒãˆæ–¹ã‚’ã¾ã¨ã‚ãŸå®Ÿç”¨çš„ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

---

## ğŸ“š ç›®æ¬¡

1. [ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æ“ä½œ](#1-ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æ“ä½œ-p-001p-003)
2. [æ¡ä»¶æŠ½å‡ºã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°](#2-æ¡ä»¶æŠ½å‡ºã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°-p-004p-009)
3. [æ–‡å­—åˆ—æ“ä½œã¨æ­£è¦è¡¨ç¾](#3-æ–‡å­—åˆ—æ“ä½œã¨æ­£è¦è¡¨ç¾-p-010p-016)
4. [ã‚½ãƒ¼ãƒˆã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°](#4-ã‚½ãƒ¼ãƒˆã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°-p-017p-020)
5. [é›†è¨ˆå‡¦ç†ã®åŸºç¤](#5-é›†è¨ˆå‡¦ç†ã®åŸºç¤-p-021p-026)
6. [çµ±è¨ˆåˆ†æ](#6-çµ±è¨ˆåˆ†æ-p-027p-035)
7. [ãƒ‡ãƒ¼ã‚¿çµåˆï¼ˆJOINï¼‰](#7-ãƒ‡ãƒ¼ã‚¿çµåˆjoin-p-036p-040)
8. [ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°ã¨ãƒ”ãƒœãƒƒãƒˆ](#8-ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°ã¨ãƒ”ãƒœãƒƒãƒˆ-p-041p-044)
9. [æ—¥ä»˜ãƒ»æ™‚åˆ»æ“ä½œï¼ˆåŸºç¤ï¼‰](#9-æ—¥ä»˜æ™‚åˆ»æ“ä½œåŸºç¤-p-045p-051)
10. [æ—¥ä»˜è¨ˆç®—ï¼ˆå¿œç”¨ï¼‰](#10-æ—¥ä»˜è¨ˆç®—å¿œç”¨-p-070p-074)
11. [ã‚«ãƒ†ã‚´ãƒªåŒ–ã¨äºŒå€¤åŒ–](#11-ã‚«ãƒ†ã‚´ãƒªåŒ–ã¨äºŒå€¤åŒ–-p-052p-058)
12. [æ­£è¦åŒ–ã¨æ¨™æº–åŒ–](#12-æ­£è¦åŒ–ã¨æ¨™æº–åŒ–-p-059p-062)
13. [ç®—è¡“æ¼”ç®—ã¨ä¸¸ã‚å‡¦ç†](#13-ç®—è¡“æ¼”ç®—ã¨ä¸¸ã‚å‡¦ç†-p-063p-068)
14. [è¤‡é›‘ãªé›†è¨ˆã¨æ¯”ç‡è¨ˆç®—](#14-è¤‡é›‘ãªé›†è¨ˆã¨æ¯”ç‡è¨ˆç®—-p-069-p-084)
15. [ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°](#15-ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°-p-075p-076)
16. [å¤–ã‚Œå€¤æ¤œå‡º](#16-å¤–ã‚Œå€¤æ¤œå‡º-p-077p-078)
17. [æ¬ æå€¤å‡¦ç†](#17-æ¬ æå€¤å‡¦ç†-p-079p-083)
18. [åœ°ç†ç©ºé–“ãƒ‡ãƒ¼ã‚¿](#18-åœ°ç†ç©ºé–“ãƒ‡ãƒ¼ã‚¿-p-085p-086)
19. [ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°](#19-ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°-p-087p-088)
20. [æ©Ÿæ¢°å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™](#20-æ©Ÿæ¢°å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™-p-089p-091)
21. [æ­£è¦åŒ–ãƒ»éæ­£è¦åŒ–](#21-æ­£è¦åŒ–éæ­£è¦åŒ–-p-092p-093)
22. [ãƒ•ã‚¡ã‚¤ãƒ«å…¥å‡ºåŠ›](#22-ãƒ•ã‚¡ã‚¤ãƒ«å…¥å‡ºåŠ›-p-094p-100)

---

## 1. ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æ“ä½œ ã€P-001ï½P-003ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - ãƒ‡ãƒ¼ã‚¿ã®ä¸­èº«ã‚’ç¢ºèªã—ãŸã„
> - ç‰¹å®šã®åˆ—ã ã‘å–ã‚Šå‡ºã—ãŸã„
> - åˆ—åã‚’å¤‰æ›´ã—ãŸã„

### ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
```python
df.head(10)          # å…ˆé ­10ä»¶ã‚’è¡¨ç¤º
df.tail(10)          # æœ«å°¾10ä»¶ã‚’è¡¨ç¤º
df.sample(10)        # ãƒ©ãƒ³ãƒ€ãƒ ã«10ä»¶ã‚’è¡¨ç¤º
df.shape             # (è¡Œæ•°, åˆ—æ•°) ã‚’ç¢ºèª
df.columns           # åˆ—åä¸€è¦§ã‚’ç¢ºèª
```

### åˆ—ã®é¸æŠ
```python
# å˜ä¸€åˆ—ã®é¸æŠï¼ˆSeriesã¨ã—ã¦å–å¾—ï¼‰
df['col']                    # çµæœ: Series

# å˜ä¸€åˆ—ã®é¸æŠï¼ˆDataFrameã¨ã—ã¦å–å¾—ï¼‰
df[['col']]                  # çµæœ: DataFrameï¼ˆåˆ—æ•°ãŒ1ã§ã‚‚ï¼‰

# è¤‡æ•°åˆ—ã®é¸æŠï¼ˆDataFrameã¨ã—ã¦å–å¾—ï¼‰
df[['col1', 'col2']]         # äºŒé‡ã®è§’æ‹¬å¼§ãŒå¿…è¦

# ç¯„å›²æŒ‡å®šã§é¸æŠ
df.loc[:, 'col1':'col3']     # col1ã‹ã‚‰col3ã¾ã§ã®å…¨åˆ—
```

### åˆ—åã®å¤‰æ›´
```python
# ç‰¹å®šã®åˆ—åã‚’å¤‰æ›´ï¼ˆå…ƒã®ãƒ‡ãƒ¼ã‚¿ã¯å¤‰æ›´ã•ã‚Œãªã„ï¼‰
df_renamed = df.rename(columns={'old': 'new'})

# å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚‚å¤‰æ›´ã™ã‚‹å ´åˆ
df.rename(columns={'old': 'new'}, inplace=True)

# å…¨åˆ—åã‚’ä¸€æ‹¬å¤‰æ›´ï¼ˆåˆ—æ•°ã¨åŒã˜æ•°ã®åå‰ãŒå¿…è¦ï¼‰
df.columns = ['new1', 'new2', 'new3']
```

---

## 2. æ¡ä»¶æŠ½å‡ºã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° ã€P-004ï½P-009ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - æ¡ä»¶ã«åˆã†ãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’æŠ½å‡ºã—ãŸã„
> - è¤‡æ•°ã®æ¡ä»¶ã‚’çµ„ã¿åˆã‚ã›ãŸã„
> - ç‰¹å®šã®å€¤ã‚’é™¤å¤–ã—ãŸã„

### query()ãƒ¡ã‚½ãƒƒãƒ‰ã®æ´»ç”¨
```python
# å˜ä¸€æ¡ä»¶
df.query('amount >= 1000')

# ANDæ¡ä»¶
df.query('amount >= 1000 & quantity >= 5')

# ORæ¡ä»¶
df.query('amount >= 1000 | quantity >= 5')

# ç¯„å›²æ¡ä»¶
df.query('1000 <= amount <= 2000')

# å¦å®šæ¡ä»¶
df.query('product_cd != "P001"')
```

### ãƒ‰ãƒ»ãƒ¢ãƒ«ã‚¬ãƒ³ã®æ³•å‰‡
```python
# not(A | B) = (not A) & (not B)
df.query('not(prefecture_cd == "13" | floor_area > 900)')
# â†“ ç­‰ä¾¡å¤‰æ›
df.query('prefecture_cd != "13" & floor_area <= 900')
```

---

## 3. æ–‡å­—åˆ—æ“ä½œã¨æ­£è¦è¡¨ç¾ ã€P-010ï½P-016ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - ã€Œã€‡ã€‡ã§å§‹ã¾ã‚‹ã€ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ãŸã„
> - ã€Œã€‡ã€‡ã‚’å«ã‚€ã€ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ãŸã„
> - é›»è©±ç•ªå·ã‚„éƒµä¾¿ç•ªå·ãªã©ç‰¹å®šã®å½¢å¼ã‚’æ¤œç´¢ã—ãŸã„

### åŸºæœ¬çš„ãªæ–‡å­—åˆ—æ¤œç´¢ï¼ˆ.strã‚’å¿…ãšä½¿ç”¨ï¼‰
```python
df.query('col.str.startswith("XXX")')    # å‰æ–¹ä¸€è‡´
df.query('col.str.endswith("XXX")')      # å¾Œæ–¹ä¸€è‡´
df.query('col.str.contains("XXX")')      # éƒ¨åˆ†ä¸€è‡´
```

### æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
```python
# å…ˆé ­ãŒç‰¹å®šæ–‡å­—
df.query("col.str.contains(r'^[A-F]')")

# æœ«å°¾ãŒæ•°å­—
df.query("col.str.contains(r'[0-9]$')")

# è¤‡åˆãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå…ˆé ­Aï½Fã€æœ«å°¾0ï½9ï¼‰
df.query("col.str.contains(r'^[A-F].*[0-9]$')")

# é›»è©±ç•ªå·å½¢å¼ï¼ˆ3æ¡-3æ¡-4æ¡ï¼‰
df.query('tel.str.contains(r"^\d{3}-\d{3}-\d{4}$")')
```

### æ­£è¦è¡¨ç¾ãƒãƒ¼ãƒˆã‚·ãƒ¼ãƒˆ
| è¨˜å· | æ„å‘³ | ä¾‹ |
|------|------|-----|
| `^` | å…ˆé ­ | `r'^ABC'` |
| `$` | æœ«å°¾ | `r'XYZ$'` |
| `.` | ä»»æ„ã®1æ–‡å­— | `r'a.c'` |
| `*` | 0å›ä»¥ä¸Š | `r'ab*c'` |
| `+` | 1å›ä»¥ä¸Š | `r'ab+c'` |
| `{n}` | nå› | `r'\d{3}'` |
| `[ABC]` | ã„ãšã‚Œã‹ | `r'[A-F]'` |
| `\d` | æ•°å­— | `r'\d{4}'` |
| `\w` | è‹±æ•°å­— | `r'\w+'` |

---

## 4. ã‚½ãƒ¼ãƒˆã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚° ã€P-017ï½P-020ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - ãƒ‡ãƒ¼ã‚¿ã‚’ä¸¦ã³æ›¿ãˆãŸã„ï¼ˆå°ã•ã„é †ã€å¤§ãã„é †ï¼‰
> - é †ä½ã‚’ã¤ã‘ãŸã„ï¼ˆåŒç‡ã®æ‰±ã„ã‚‚å«ã‚ã¦ï¼‰
> - TOP5ã‚„ãƒ¯ãƒ¼ã‚¹ãƒˆ10ã‚’å–ã‚Šå‡ºã—ãŸã„

### ã‚½ãƒ¼ãƒˆ
```python
df.sort_values('col')                              # æ˜‡é †ï¼ˆå°ã•ã„é †ã€å¤ã„é †ï¼‰
df.sort_values('col', ascending=False)             # é™é †ï¼ˆå¤§ãã„é †ã€æ–°ã—ã„é †ï¼‰
df.sort_values(['col1', 'col2'], ascending=[True, False])  # è¤‡æ•°åˆ—
```

### ãƒ©ãƒ³ã‚­ãƒ³ã‚°
```python
df['rank'] = df['amount'].rank(method='min', ascending=False)
```

### rankãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆ[10, 20, 20, 30]ã®ä¾‹ï¼‰
| method | çµæœ | ç”¨é€” |
|--------|------|------|
| `'min'` | [1, 2, 2, 4] | åŒå€¤ã¯æœ€å°é †ä½ï¼ˆç«¶æŠ€é †ä½ï¼‰ |
| `'max'` | [1, 3, 3, 4] | åŒå€¤ã¯æœ€å¤§é †ä½ |
| `'first'` | [1, 2, 3, 4] | å‡ºç¾é †ã«ç•°ãªã‚‹é †ä½ |
| `'dense'` | [1, 2, 2, 3] | ã‚®ãƒ£ãƒƒãƒ—ãªã—é †ä½ |
| `'average'` | [1, 2.5, 2.5, 4] | å¹³å‡é †ä½ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ |

---

## 5. é›†è¨ˆå‡¦ç†ã®åŸºç¤ ã€P-021ï½P-026ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - ä»¶æ•°ã‚’æ•°ãˆãŸã„
> - ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«åˆè¨ˆãƒ»å¹³å‡ã‚’å‡ºã—ãŸã„
> - ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®æ•°ã‚’çŸ¥ã‚ŠãŸã„

### ã‚«ã‚¦ãƒ³ãƒˆ
```python
len(df)                              # ç·ä»¶æ•°
df['col'].nunique()                  # ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°
df['col'].value_counts()             # å€¤ã”ã¨ã®ä»¶æ•°
```

### groupbyé›†è¨ˆ
```python
# å˜ä¸€é–¢æ•°
df.groupby('col')['amount'].sum()

# è¤‡æ•°åˆ—
df.groupby('col')[['amount', 'quantity']].sum()

# è¤‡æ•°é–¢æ•°
df.groupby('col').agg({'amount': 'sum', 'date': 'max'})

# åŒã˜åˆ—ã«è¤‡æ•°é–¢æ•°
df.groupby('col').agg({'date': ['max', 'min']})

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
df.groupby('col').agg({'amount': 'sum'}).reset_index()
```

### ä¸»ãªé›†è¨ˆé–¢æ•°
| é–¢æ•° | èª¬æ˜ |
|------|------|
| `sum()` | åˆè¨ˆ |
| `mean()` | å¹³å‡ |
| `median()` | ä¸­å¤®å€¤ |
| `mode()` | æœ€é »å€¤ |
| `min()` / `max()` | æœ€å°/æœ€å¤§ |
| `std()` | æ¨™æº–åå·® |
| `var()` | åˆ†æ•£ |
| `count()` | ä»¶æ•° |

---

## 6. çµ±è¨ˆåˆ†æ ã€P-027ï½P-035ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - å¹³å‡å€¤ãƒ»ä¸­å¤®å€¤ãƒ»æœ€é »å€¤ã‚’è¨ˆç®—ã—ãŸã„
> - åˆ†æ•£ãƒ»æ¨™æº–åå·®ã‚’æ±‚ã‚ãŸã„
> - ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼ˆå››åˆ†ä½ç‚¹ï¼‰ã‚’çŸ¥ã‚ŠãŸã„
> - å¹³å‡ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’æŠ½å‡ºã—ãŸã„

### åŸºæœ¬çµ±è¨ˆé‡
```python
df['amount'].mean()           # å¹³å‡
df['amount'].median()         # ä¸­å¤®å€¤
df['amount'].mode()           # æœ€é »å€¤ï¼ˆè¤‡æ•°ã‚ã‚‹å ´åˆã¯å…¨ã¦è¿”ã‚‹ï¼‰
df['amount'].mode()[0]        # æœ€é »å€¤ï¼ˆæœ€åˆã®å€¤ã®ã¿å–å¾—ï¼‰
df['amount'].var()            # åˆ†æ•£ï¼ˆä¸ååˆ†æ•£: n-1ã§å‰²ã‚‹ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
df['amount'].var(ddof=0)      # æ¯åˆ†æ•£ï¼ˆnã§å‰²ã‚‹ï¼‰
df['amount'].std()            # æ¨™æº–åå·®ï¼ˆä¸åæ¨™æº–åå·®: n-1ã§å‰²ã‚‹ï¼‰
df['amount'].std(ddof=0)      # æ¯æ¨™æº–åå·®ï¼ˆnã§å‰²ã‚‹ï¼‰
```

**â— æ³¨æ„**: Pandas/NumPyã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä¸åæ¨å®šé‡ï¼ˆddof=1ï¼‰ã€‚æ¯é›†å›£ã®åˆ†æ•£/æ¨™æº–åå·®ã‚’æ±‚ã‚ã‚‹å ´åˆã¯ddof=0ã‚’æŒ‡å®š

### ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼ˆç™¾åˆ†ä½æ•°ï¼‰
```python
# å››åˆ†ä½ç‚¹ï¼ˆ25%, 50%, 75%ï¼‰ã‚’å–å¾—
np.percentile(df['amount'], [25, 50, 75])        # NumPyç‰ˆ
df['amount'].quantile([0.25, 0.5, 0.75])          # Pandasç‰ˆ

# ç‰¹å®šã®ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å€¤ã‚’å–å¾—
df['amount'].quantile(0.9)  # 90ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å€¤
```

### æ¡ä»¶ä»˜ãé›†è¨ˆ
```python
# å¹³å‡ä»¥ä¸Šã®æŠ½å‡º
mean_val = df['amount'].mean()
df.query('amount >= @mean_val')

# ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥æ¡ä»¶
df_agg = df.groupby('store_cd')['amount'].mean().reset_index()
df_agg.query('amount >= 330')
```

**ğŸ’¡ è€ƒãˆæ–¹**: çµ±è¨ˆé‡ã‚’å…ˆã«è¨ˆç®—ã—ã¦ã‹ã‚‰ã€ãã‚Œã‚’æ¡ä»¶ã«ä½¿ã†2æ®µéšå‡¦ç†ãŒåŸºæœ¬

---

## 7. ãƒ‡ãƒ¼ã‚¿çµåˆï¼ˆJOINï¼‰ ã€P-036ï½P-040ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - 2ã¤ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚­ãƒ¼ã§ç´ã¥ã‘ãŸã„
> - ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦åç§°ã‚’ä»˜ã‘ãŸã„
> - ç‰‡æ–¹ã«ã—ã‹ãªã„ãƒ‡ãƒ¼ã‚¿ã‚‚å«ã‚ã¦çµåˆã—ãŸã„

### mergeã®åŸºæœ¬
```python
# INNER JOINï¼ˆä¸¡æ–¹ã«å­˜åœ¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
pd.merge(df1, df2, on='key', how='inner')

# LEFT JOINï¼ˆå·¦å´ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¨ã¦ä¿æŒï¼‰
pd.merge(df1, df2, on='key', how='left')

# OUTER JOINï¼ˆä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¨ã¦ä¿æŒï¼‰
pd.merge(df1, df2, on='key', how='outer')

# è¤‡æ•°ã‚­ãƒ¼
pd.merge(df1, df2, on=['key1', 'key2'], how='inner')

# åˆ—åãŒç•°ãªã‚‹å ´åˆ
pd.merge(df1, df2, left_on='id1', right_on='id2', how='inner')
```

### ã‚¯ãƒ­ã‚¹ã‚¸ãƒ§ã‚¤ãƒ³ï¼ˆç›´ç©ï¼‰
```python
# ãƒ€ãƒŸãƒ¼ã‚­ãƒ¼ã‚’ä½¿ç”¨
df1['key'] = 0
df2['key'] = 0
df_cross = pd.merge(df1, df2, on='key').drop('key', axis=1)
```

### æ¬ æå€¤ã®æ‰±ã„
```python
# çµåˆå¾Œã®æ¬ æã‚’0ã§åŸ‹ã‚ã‚‹
pd.merge(df1, df2, on='key', how='left').fillna(0)
```

**ğŸ’¡ è€ƒãˆæ–¹**: 
- ã€Œã©ã¡ã‚‰ã‚’åŸºæº–ã«ã™ã‚‹ã‹ã€ã§howã‚’æ±ºã‚ã‚‹
- LEFT JOINã¯ã€Œå·¦å´ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’æ®‹ã—ãŸã„ã€ã¨ã
- INNER JOINã¯ã€Œä¸¡æ–¹ã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã ã‘ã€æ¬²ã—ã„ã¨ã

---

## 8. ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°ã¨ãƒ”ãƒœãƒƒãƒˆ ã€P-041ï½P-044ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - å‰æ—¥æ¯”ãƒ»å‰æœˆæ¯”ã‚’è¨ˆç®—ã—ãŸã„
> - ç¸¦æ¨ªã‚’å…¥ã‚Œæ›¿ãˆãŸã‚¯ãƒ­ã‚¹é›†è¨ˆè¡¨ã‚’ä½œã‚ŠãŸã„
> - æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã€Œ1ã¤å‰ã€ã€Œ2ã¤å‰ã€ã‚’å‚ç…§ã—ãŸã„

### shift()ã«ã‚ˆã‚‹å‰å›å€¤å‚ç…§
```python
# 1ã¤å‰ã®è¡Œã‚’å‚ç…§
df['prev_amount'] = df['amount'].shift(1)

# å·®åˆ†è¨ˆç®—
df['diff'] = df['amount'] - df['amount'].shift(1)

# ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§shift
df['prev_in_group'] = df.groupby('store_cd')['amount'].shift(1)
```

### ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«
```python
# é›†è¨ˆè¡¨ã®ä½œæˆ
df.pivot_table(
    values='amount',      # é›†è¨ˆã™ã‚‹å€¤
    index='gender',       # è¡Œ
    columns='age_group',  # åˆ—
    aggfunc='sum',        # é›†è¨ˆé–¢æ•°
    fill_value=0          # æ¬ æå€¤ã®åŸ‹ã‚æ–¹
)
```

### ç¸¦æŒã¡â†”æ¨ªæŒã¡å¤‰æ›
```python
# æ¨ªæŒã¡ â†’ ç¸¦æŒã¡
df_long = df.stack().reset_index()

# ç¸¦æŒã¡ â†’ æ¨ªæŒã¡
df_wide = df.pivot(index='id', columns='category', values='value')
```

**ğŸ’¡ è€ƒãˆæ–¹**: 
- shift()ã¯ã€Œå‰ã®è¡Œã¨æ¯”è¼ƒã—ãŸã„ã€æ™‚ã«ä½¿ã†
- pivot_tableã¯ã€Œ2è»¸ã§ã‚¯ãƒ­ã‚¹é›†è¨ˆã—ãŸã„ã€æ™‚ã«ä½¿ã†

---

## 9. æ—¥ä»˜ãƒ»æ™‚åˆ»æ“ä½œï¼ˆåŸºç¤ï¼‰ ã€P-045ï½P-051ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - æ–‡å­—åˆ—ã‚„æ•°å€¤ã‚’æ—¥ä»˜å‹ã«å¤‰æ›ã—ãŸã„
> - æ—¥ä»˜ã‹ã‚‰å¹´ãƒ»æœˆãƒ»æ—¥ã‚’å–ã‚Šå‡ºã—ãŸã„
> - æ—¥ä»˜ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å¤‰æ›ã—ãŸã„ï¼ˆYYYYMMDDâ†’YYYY-MM-DDãªã©ï¼‰

### æ—¥ä»˜å‹ã¸ã®å¤‰æ›
```python
# æ–‡å­—åˆ— â†’ æ—¥ä»˜å‹
pd.to_datetime(df['date_str'], format='%Y%m%d')
pd.to_datetime('20190101', format='%Y%m%d')

# æ•°å€¤ â†’ æ—¥ä»˜å‹
pd.to_datetime(df['date_int'], format='%Y%m%d')

# ã‚¨ãƒãƒƒã‚¯ç§’ â†’ æ—¥ä»˜å‹
pd.to_datetime(df['epoch'], unit='s')
```

### æ—¥ä»˜å‹ã‹ã‚‰ã®å¤‰æ›
```python
# æ—¥ä»˜å‹ â†’ æ–‡å­—åˆ—ï¼ˆYYYYMMDDå½¢å¼ï¼‰
df['date'].dt.strftime('%Y%m%d')

# æ—¥ä»˜å‹ â†’ æ–‡å­—åˆ—ï¼ˆ0åŸ‹ã‚ãªã—ï¼‰
df['date'].astype('str').str.replace('-', '')
```

### å¹´æœˆæ—¥ã®æŠ½å‡º
```python
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day

# 0åŸ‹ã‚æ–‡å­—åˆ—ã¨ã—ã¦å–å¾—
df['month_str'] = df['date'].dt.strftime('%m')
df['day_str'] = df['date'].dt.strftime('%d')
```

### ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨˜å·
| è¨˜å· | æ„å‘³ | ä¾‹ |
|------|------|-----|
| `%Y` | 4æ¡å¹´ | 2019 |
| `%m` | 2æ¡æœˆï¼ˆ0åŸ‹ã‚ï¼‰ | 01 |
| `%d` | 2æ¡æ—¥ï¼ˆ0åŸ‹ã‚ï¼‰ | 09 |
| `%H` | 2æ¡æ™‚ï¼ˆ0åŸ‹ã‚ï¼‰ | 14 |
| `%M` | 2æ¡åˆ†ï¼ˆ0åŸ‹ã‚ï¼‰ | 30 |
| `%S` | 2æ¡ç§’ï¼ˆ0åŸ‹ã‚ï¼‰ | 45 |

**ğŸ’¡ è€ƒãˆæ–¹**: æ—¥ä»˜ã¯å¿…ãš`datetime`å‹ã«å¤‰æ›ã—ã¦ã‹ã‚‰æ“ä½œã™ã‚‹

---

## 10. æ—¥ä»˜è¨ˆç®—ï¼ˆå¿œç”¨ï¼‰ ã€P-070ï½P-074ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - ç™»éŒ²æ—¥ã‹ã‚‰ä½•æ—¥/ä½•ãƒ¶æœˆ/ä½•å¹´çµŒéã—ãŸã‹è¨ˆç®—ã—ãŸã„
> - 2ã¤ã®æ—¥ä»˜ã®å·®ã‚’æ±‚ã‚ãŸã„
> - æ›œæ—¥ã‚’å–å¾—ã—ãŸã„ / é€±ã®é–‹å§‹æ—¥ã‚’æ±‚ã‚ãŸã„

### çµŒéæœŸé–“ã®è¨ˆç®—
```python
from dateutil.relativedelta import relativedelta

# åŸºæº–æ—¥ã‚’è¨­å®š
base_date = pd.to_datetime('2019-04-01')

# çµŒéæ—¥æ•°
(base_date - df['date']).dt.days

# çµŒéæœˆæ•°
df['date'].apply(lambda x: relativedelta(base_date, x).months)

# çµŒéå¹´æ•°
df['date'].apply(lambda x: relativedelta(base_date, x).years)
```

### ã‚¨ãƒãƒƒã‚¯ç§’ã«ã‚ˆã‚‹çµŒéæ™‚é–“
```python
# æ—¥ä»˜ â†’ ã‚¨ãƒãƒƒã‚¯ç§’
epoch = df['date'].astype(np.int64) // 10**9

# çµŒéç§’æ•°
base_epoch = pd.to_datetime('2019-04-01').value // 10**9
elapsed_seconds = base_epoch - epoch

# ç§’ â†’ æ—¥
elapsed_days = elapsed_seconds / (60 * 60 * 24)
```

### æ›œæ—¥è¨ˆç®—
```python
# 0=æœˆæ›œæ—¥, 6=æ—¥æ›œæ—¥
df['weekday'] = df['date'].dt.weekday()

# é€±ã®æœˆæ›œæ—¥ã‚’å–å¾—
df['monday'] = df['date'] - pd.to_timedelta(df['date'].dt.weekday(), unit='D')

# æœˆæ›œæ—¥ã‹ã‚‰ã®çµŒéæ—¥æ•°
df['days_from_monday'] = df['date'].dt.weekday()
```

**ğŸ’¡ è€ƒãˆæ–¹**: 
- æ—¥æ•° â†’ `dt.days`
- æœˆæ•°/å¹´æ•° â†’ `relativedelta()`
- é€±ã®è¨ˆç®— â†’ `dt.weekday()`

---

## 11. ã‚«ãƒ†ã‚´ãƒªåŒ–ã¨äºŒå€¤åŒ– ã€P-052ï½P-058ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - æ•°å€¤ã‚’ã€Œé«˜ã„/ä½ã„ã€ã®2ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†ã‘ãŸã„
> - å¹´é½¢ã‚’å¹´ä»£ï¼ˆ10ä»£ã€20ä»£...ï¼‰ã«å¤‰æ›ã—ãŸã„
> - ã‚«ãƒ†ã‚´ãƒªã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°ï¼ˆ0/1ï¼‰ã«å¤‰æ›ã—ãŸã„
> - å€¤ã‚’åˆ¥ã®å€¤ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã—ãŸã„ï¼ˆã‚³ãƒ¼ãƒ‰â†’åç§°ãªã©ï¼‰

### äºŒå€¤åŒ–ï¼ˆé–¾å€¤ãƒ™ãƒ¼ã‚¹ï¼‰
```python
# å˜ç´”ãªäºŒå€¤åŒ–
df['is_high'] = (df['amount'] >= 2000).astype(int)

# np.whereã§æ¡ä»¶åˆ†å²
df['category'] = np.where(df['amount'] >= 2000, 'high', 'low')
```

### map()ã«ã‚ˆã‚‹å¤‰æ›
```python
# è¾æ›¸ã§å¤‰æ›
prefecture_dict = {
    '13': 'æ±äº¬éƒ½',
    '14': 'ç¥å¥ˆå·çœŒ',
    # ...
}
df['prefecture_name'] = df['prefecture_cd'].map(prefecture_dict)
```

### å››åˆ†ä½ã«ã‚ˆã‚‹ã‚«ãƒ†ã‚´ãƒªåŒ–
```python
# ç­‰é »åº¦åˆ†å‰²ï¼ˆqcutï¼‰
df['quartile'] = pd.qcut(df['amount'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])

# ç­‰é–“éš”åˆ†å‰²ï¼ˆcutï¼‰
df['category'] = pd.cut(df['amount'], bins=[0, 1000, 2000, 3000, 10000], 
                         labels=['low', 'mid', 'high', 'very_high'])
```

### å¹´é½¢ã‹ã‚‰å¹´ä»£ã®ç®—å‡º
```python
# 10æ­³åˆ»ã¿ï¼ˆ60æ­³ä»¥ä¸Šã¯60ä»£ï¼‰
df['age_group'] = np.minimum((df['age'] // 10) * 10, 60)

# ãƒ©ãƒ™ãƒ«ä»˜ã
df['age_group'] = pd.cut(df['age'], 
                          bins=[0, 10, 20, 30, 40, 50, 60, 100],
                          labels=['0-9', '10s', '20s', '30s', '40s', '50s', '60+'],
                          right=False)
```

### ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ï¼ˆOne-Hot Encodingï¼‰
```python
# ã‚«ãƒ†ã‚´ãƒªåˆ—ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«å¤‰æ›
pd.get_dummies(df['gender_cd'], prefix='gender')

# çµæœï¼šgender_0, gender_1ã®ã‚ˆã†ãªåˆ—ãŒç”Ÿæˆã•ã‚Œã‚‹
```

**ğŸ’¡ è€ƒãˆæ–¹**:
- é–¾å€¤ãŒã‚ã‚‹ â†’ äºŒå€¤åŒ–
- åŒºé–“ã§åˆ†ã‘ãŸã„ â†’ `cut()` / `qcut()`
- ã‚«ãƒ†ã‚´ãƒªâ†’æ•°å€¤ â†’ ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–

---

## 12. æ­£è¦åŒ–ã¨æ¨™æº–åŒ– ã€P-059ï½P-062ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã®å€¤ã‚’æƒãˆãŸã„ï¼ˆæ©Ÿæ¢°å­¦ç¿’ã®å‰å‡¦ç†ï¼‰
> - å€¤ã‚’0ã€œ1ã®ç¯„å›²ã«åã‚ãŸã„
> - æ­ªã‚“ã åˆ†å¸ƒã‚’æ­£è¦åˆ†å¸ƒã«è¿‘ã¥ã‘ãŸã„

### æ¨™æº–åŒ–ï¼ˆZ-score normalizationï¼‰
å¹³å‡0ã€æ¨™æº–åå·®1ã«å¤‰æ›ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ãŒç•°ãªã‚‹ç‰¹å¾´é‡ã‚’æ¯”è¼ƒå¯èƒ½ã«ï¼‰
```python
from sklearn.preprocessing import StandardScaler

# NumPyç‰ˆ
from sklearn import preprocessing
df['amount_std'] = preprocessing.scale(df['amount'])

# Scikit-learnç‰ˆ
scaler = StandardScaler()
df['amount_std'] = scaler.fit_transform(df[['amount']])
```

### æ­£è¦åŒ–ï¼ˆMin-Max normalizationï¼‰
æœ€å°å€¤0ã€æœ€å¤§å€¤1ã«å¤‰æ›
```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
df['amount_norm'] = scaler.fit_transform(df[['amount']])
```

### å¯¾æ•°å¤‰æ›
```python
# å¸¸ç”¨å¯¾æ•°ï¼ˆåº•10ï¼‰
df['amount_log10'] = np.log10(df['amount'])

# è‡ªç„¶å¯¾æ•°ï¼ˆåº•eï¼‰
df['amount_ln'] = np.log(df['amount'])
```

**ğŸ’¡ è€ƒãˆæ–¹**:
- ã‚¹ã‚±ãƒ¼ãƒ«ã‚’æƒãˆãŸã„ â†’ æ¨™æº–åŒ–/æ­£è¦åŒ–
- åˆ†å¸ƒã‚’æ­£è¦åˆ†å¸ƒã«è¿‘ã¥ã‘ãŸã„ â†’ å¯¾æ•°å¤‰æ›
- å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’æŠ‘ãˆãŸã„ â†’ å¯¾æ•°å¤‰æ›

---

## 13. ç®—è¡“æ¼”ç®—ã¨ä¸¸ã‚å‡¦ç† ã€P-063ï½P-068ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - åˆ—åŒå£«ã‚’è¨ˆç®—ã—ã¦æ–°ã—ã„åˆ—ã‚’ä½œã‚ŠãŸã„ï¼ˆåˆ©ç›Šç‡ãªã©ï¼‰
> - ç¨è¾¼ä¾¡æ ¼ã‚’è¨ˆç®—ã—ãŸã„
> - å°æ•°ç‚¹ä»¥ä¸‹ã‚’åˆ‡ã‚Šæ¨ã¦/åˆ‡ã‚Šä¸Šã’/å››æ¨äº”å…¥ã—ãŸã„

### åŸºæœ¬æ¼”ç®—
```python
# åˆ©ç›Šé¡ = å˜ä¾¡ - åŸä¾¡
df['profit'] = df['unit_price'] - df['unit_cost']

# åˆ©ç›Šç‡ = åˆ©ç›Šé¡ / å˜ä¾¡
df['profit_rate'] = df['profit'] / df['unit_price']

# å¹³å‡ï¼ˆæ¬ æå€¤ã‚’ç„¡è¦–ï¼‰
df['amount'].mean(skipna=True)
```

### ä¸¸ã‚å‡¦ç†
```python
# åˆ‡ã‚Šæ¨ã¦
df['price_floor'] = np.floor(df['price'])

# å››æ¨äº”å…¥
df['price_round'] = np.round(df['price'])

# åˆ‡ã‚Šä¸Šã’
df['price_ceil'] = np.ceil(df['price'])
```

### å®Ÿç”¨ä¾‹ï¼šç¨è¾¼ä¾¡æ ¼ã®è¨ˆç®—
```python
# æ¶ˆè²»ç¨10%è¾¼ã¿ã®ä¾¡æ ¼ï¼ˆ1å††æœªæº€åˆ‡ã‚Šæ¨ã¦ï¼‰
df['price_with_tax'] = np.floor(df['price'] * 1.1)
```

**ğŸ’¡ è€ƒãˆæ–¹**: é‡‘é¡è¨ˆç®—ã¯å¿…ãšä¸¸ã‚å‡¦ç†ã‚’æ„è­˜ã™ã‚‹

---

## 14. è¤‡é›‘ãªé›†è¨ˆã¨æ¯”ç‡è¨ˆç®— ã€P-069, P-084ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - å…¨ä½“ã«å ã‚ã‚‹å‰²åˆã‚’è¨ˆç®—ã—ãŸã„
> - ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®æ§‹æˆæ¯”ã‚’å‡ºã—ãŸã„
> - ç‰¹å®šæœŸé–“ã¨å…¨æœŸé–“ã‚’æ¯”è¼ƒã—ãŸã„

### è¤‡æ•°ãƒ¬ãƒ™ãƒ«ã®é›†è¨ˆã¨çµåˆ
```python
# å…¨ä½“ã®å£²ä¸Š
total_sales = df.groupby('product_cd')['amount'].sum().reset_index()
total_sales.columns = ['product_cd', 'total_amount']

# ã‚«ãƒ†ã‚´ãƒªåˆ¥å£²ä¸Š
category_sales = df.groupby(['product_cd', 'category'])['amount'].sum().reset_index()
category_sales.columns = ['product_cd', 'category', 'category_amount']

# çµåˆã—ã¦æ¯”ç‡è¨ˆç®—
result = pd.merge(category_sales, total_sales, on='product_cd')
result['ratio'] = result['category_amount'] / result['total_amount']
```

### æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ã¨æ¯”ç‡
```python
# å…¨æœŸé–“ã®å£²ä¸Š
all_period = df.groupby('customer_id')['amount'].sum().reset_index()
all_period.columns = ['customer_id', 'total_amount']

# ç‰¹å®šæœŸé–“ã®å£²ä¸Š
df_2019 = df.query('20190101 <= sales_ymd <= 20191231')
period_sales = df_2019.groupby('customer_id')['amount'].sum().reset_index()
period_sales.columns = ['customer_id', 'period_amount']

# çµåˆã—ã¦æ¯”ç‡
result = pd.merge(all_period, period_sales, on='customer_id', how='left').fillna(0)
result['ratio'] = result['period_amount'] / result['total_amount']
```

**ğŸ’¡ è€ƒãˆæ–¹**: 
1. åˆ†æ¯ã¨ãªã‚‹é›†è¨ˆã‚’ä½œã‚‹
2. åˆ†å­ã¨ãªã‚‹é›†è¨ˆã‚’ä½œã‚‹
3. mergeã—ã¦æ¯”ç‡ã‚’è¨ˆç®—
4. æ¬ æå€¤å‡¦ç†ã‚’å¿˜ã‚Œãšã«

---

## 15. ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ã€P-075ï½P-076ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«æŠ½å‡ºã—ãŸã„
> - ã‚«ãƒ†ã‚´ãƒªã®æ¯”ç‡ã‚’ä¿ã£ãŸã¾ã¾æŠ½å‡ºã—ãŸã„ï¼ˆå±¤åŒ–æŠ½å‡ºï¼‰
> - å­¦ç¿’ç”¨ã«ä¸€éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šå‡ºã—ãŸã„

### ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
```python
# 1%æŠ½å‡º
df_sample = df.sample(frac=0.01, random_state=42)

# 100ä»¶æŠ½å‡º
df_sample = df.sample(n=100, random_state=42)
```

### å±¤åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
```python
from sklearn.model_selection import train_test_split

# æ€§åˆ¥ã§å±¤åŒ–ã—ã¦10%æŠ½å‡º
df_sample, _ = train_test_split(
    df, 
    test_size=0.9,           # 90%ã‚’æ¨ã¦ã‚‹ = 10%æ®‹ã™
    stratify=df['gender'],   # æ€§åˆ¥æ¯”ç‡ã‚’ä¿æŒ
    random_state=42
)
```

**ğŸ’¡ è€ƒãˆæ–¹**:
- å˜ç´”ãƒ©ãƒ³ãƒ€ãƒ  â†’ `sample()`
- ã‚«ãƒ†ã‚´ãƒªæ¯”ç‡ã‚’ä¿æŒ â†’ å±¤åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

---

## 16. å¤–ã‚Œå€¤æ¤œå‡º ã€P-077ï½P-078ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - ç•°å¸¸ã«å¤§ãã„/å°ã•ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã¤ã‘ãŸã„
> - å¤–ã‚Œå€¤ã‚’é™¤å¤–ã—ã¦ã‹ã‚‰åˆ†æã—ãŸã„
> - ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ã—ãŸã„

### 3Ïƒæ³•ï¼ˆæ¨™æº–åå·®ã«ã‚ˆã‚‹æ¤œå‡ºï¼‰
å¹³å‡ã‹ã‚‰æ¨™æº–åå·®ã®3å€ä»¥ä¸Šé›¢ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’å¤–ã‚Œå€¤ã¨ã¿ãªã™
```python
# å¯¾æ•°å¤‰æ›å¾Œã«æ¨™æº–åŒ–ï¼ˆé‡‘é¡ãªã©æ­ªã‚“ã åˆ†å¸ƒã®å ´åˆï¼‰
from sklearn import preprocessing
df['log_amount'] = np.log(df['amount'] + 1)  # +1ã¯0ã‚’é¿ã‘ã‚‹ãŸã‚
df['amount_std'] = preprocessing.scale(df['log_amount'])

# |Z| > 3 ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¤–ã‚Œå€¤ã¨ã—ã¦æŠ½å‡º
df_outliers = df.query('abs(amount_std) > 3')

# å¤–ã‚Œå€¤ã‚’é™¤å¤–ã™ã‚‹å ´åˆ
df_clean = df.query('abs(amount_std) <= 3')
```

### IQRæ³•ï¼ˆå››åˆ†ä½ç¯„å›²ã«ã‚ˆã‚‹æ¤œå‡ºï¼‰
ç¬¬1å››åˆ†ä½ï¼ˆQ1ï¼‰ã¨ç¬¬3å››åˆ†ä½ï¼ˆQ3ï¼‰ã®å·®ï¼ˆIQRï¼‰ã‚’1.5å€ã—ãŸç¯„å›²å¤–ã‚’å¤–ã‚Œå€¤ã¨ã¿ãªã™
```python
# å››åˆ†ä½ç‚¹ã‚’è¨ˆç®—
q1 = df['amount'].quantile(0.25)  # 25%ç‚¹
q3 = df['amount'].quantile(0.75)  # 75%ç‚¹
iqr = q3 - q1                      # å››åˆ†ä½ç¯„å›²

# å¤–ã‚Œå€¤ã®å¢ƒç•Œã‚’è¨ˆç®—
lower_bound = q1 - 1.5 * iqr  # ä¸‹é™
upper_bound = q3 + 1.5 * iqr  # ä¸Šé™

# å¤–ã‚Œå€¤æŠ½å‡º
df_outliers = df.query('amount < @lower_bound or amount > @upper_bound')

# å¤–ã‚Œå€¤ã‚’é™¤å¤–
df_clean = df.query('@lower_bound <= amount <= @upper_bound')
```

**ğŸ’¡ è€ƒãˆæ–¹**:
- æ­£è¦åˆ†å¸ƒã«è¿‘ã„ â†’ 3Ïƒæ³•
- åˆ†å¸ƒãŒåã£ã¦ã„ã‚‹ â†’ IQRæ³•ï¼ˆãƒ­ãƒã‚¹ãƒˆï¼‰

---

## 17. æ¬ æå€¤å‡¦ç† ã€P-079ï½P-083ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - ãƒ‡ãƒ¼ã‚¿ã«æ¬ æï¼ˆNaNï¼‰ãŒã‚ã‚‹ã‹ç¢ºèªã—ãŸã„
> - æ¬ æãŒã‚ã‚‹è¡Œã‚’å‰Šé™¤ã—ãŸã„
> - æ¬ æã‚’å¹³å‡å€¤ã‚„ä¸­å¤®å€¤ã§åŸ‹ã‚ãŸã„

### æ¬ æå€¤ã®ç¢ºèª
```python
# æ¬ ææ•°ã®ã‚«ã‚¦ãƒ³ãƒˆ
df.isnull().sum()

# æ¬ æç‡
df.isnull().mean()

# æ¬ æãŒã‚ã‚‹è¡Œã‚’æŠ½å‡º
df[df['col'].isnull()]
```

### æ¬ æå€¤ã®å‰Šé™¤
```python
# æ¬ æãŒã‚ã‚‹è¡Œã‚’å‰Šé™¤
df.dropna(subset=['col'])

# å…¨ã¦ã®åˆ—ã§æ¬ æãŒãªã„è¡Œã®ã¿
df.dropna()
```

### æ¬ æå€¤ã®è£œå®Œ
```python
# å¹³å‡å€¤ã§è£œå®Œ
df['col'].fillna(df['col'].mean())

# ä¸­å¤®å€¤ã§è£œå®Œ
df['col'].fillna(df['col'].median())

# Scikit-learnã§è£œå®Œ
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')  # or 'median', 'most_frequent'
df['col'] = imputer.fit_transform(df[['col']])
```

### ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã®è£œå®Œ
```python
# ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ä¸­å¤®å€¤ã§è£œå®Œ
df['amount'] = df.groupby('category')['amount'].transform(
    lambda x: x.fillna(x.median())
)

# æ¬ æã ã‘ã‚’æ›¸ãæ›ãˆã‚‹
df['amount'] = df['amount'].mask(
    df['amount'].isnull(),
    df.groupby('category')['amount'].transform('median')
)
```

**ğŸ’¡ è€ƒãˆæ–¹**:
- æ¬ æãŒå°‘ãªã„ â†’ å‰Šé™¤ã‚‚é¸æŠè‚¢
- æ¬ æãŒå¤šã„ â†’ è£œå®Œå¿…é ˆ
- ã‚°ãƒ«ãƒ¼ãƒ—é–“ã§ç‰¹æ€§ãŒé•ã† â†’ ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥è£œå®Œ

---

## 18. åœ°ç†ç©ºé–“ãƒ‡ãƒ¼ã‚¿ ã€P-085ï½P-086ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - éƒµä¾¿ç•ªå·ã‹ã‚‰ç·¯åº¦çµŒåº¦ã‚’å–å¾—ã—ãŸã„
> - 2åœ°ç‚¹é–“ã®è·é›¢ã‚’è¨ˆç®—ã—ãŸã„
> - åº—èˆ—ã¨é¡§å®¢ã®è·é›¢ã‚’æ±‚ã‚ãŸã„

### ç·¯åº¦çµŒåº¦ãƒ‡ãƒ¼ã‚¿ã®çµåˆ
```python
# éƒµä¾¿ç•ªå·ã”ã¨ã«çµŒç·¯åº¦ã‚’å¹³å‡
geocode_avg = df_geocode.groupby('postal_cd').agg({
    'latitude': 'mean',
    'longitude': 'mean'
}).reset_index()

# é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã«çµåˆ
df_customer = pd.merge(df_customer, geocode_avg, on='postal_cd', how='left')
```

### 2ç‚¹é–“ã®è·é›¢è¨ˆç®—ï¼ˆçƒé¢ä¸‰è§’æ³•ï¼‰
```python
import math

def calc_distance(lat1, lon1, lat2, lon2):
    """2ç‚¹é–“ã®è·é›¢ã‚’è¨ˆç®—ï¼ˆkmå˜ä½ï¼‰"""
    # åº¦ã‚’ãƒ©ã‚¸ã‚¢ãƒ³ã«å¤‰æ›
    lat1_r = math.radians(lat1)
    lon1_r = math.radians(lon1)
    lat2_r = math.radians(lat2)
    lon2_r = math.radians(lon2)
    
    # çƒé¢ä¸‰è§’æ³•ã®å…¬å¼
    cos_d = math.sin(lat1_r) * math.sin(lat2_r) + \
            math.cos(lat1_r) * math.cos(lat2_r) * math.cos(lon1_r - lon2_r)
    
    # åœ°çƒã®åŠå¾„ï¼ˆkmï¼‰Ã— è§’åº¦ = è·é›¢
    distance = 6371 * math.acos(cos_d)
    return distance

# DataFrameã«é©ç”¨
df['distance'] = df.apply(
    lambda row: calc_distance(row['lat1'], row['lon1'], row['lat2'], row['lon2']),
    axis=1
)
```

**ğŸ’¡ è€ƒãˆæ–¹**:
- ç·¯åº¦çµŒåº¦ã¯å¿…ãšåº¦â†’ãƒ©ã‚¸ã‚¢ãƒ³å¤‰æ›
- çƒé¢ä¸Šã®è·é›¢ã¯ä¸‰è§’é–¢æ•°ã§è¨ˆç®—
- åœ°çƒã®åŠå¾„ â‰ˆ 6371km

---

## 19. ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚° ã€P-087ï½P-088ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - é‡è¤‡ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’1ã¤ã«ã¾ã¨ã‚ãŸã„ï¼ˆåå¯„ã›ï¼‰
> - åŒä¸€äººç‰©ã«çµ±åˆIDã‚’æŒ¯ã‚ŠãŸã„
> - è¡¨è¨˜ã‚†ã‚Œã‚’çµ±ä¸€ã—ãŸã„

### åå¯„ã›ï¼ˆé‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆï¼‰
```python
# åŒåãƒ»åŒéƒµä¾¿ç•ªå·ã®é¡§å®¢ã‚’çµ±åˆï¼ˆå£²ä¸Šæœ€å¤§ã‚’ä»£è¡¨ï¼‰
df_sorted = df.sort_values(['customer_name', 'postal_cd', 'total_amount'], 
                           ascending=[True, True, False])

# æœ€åˆã®è¡Œã®ã¿æ®‹ã™
df_unique = df_sorted.drop_duplicates(subset=['customer_name', 'postal_cd'], 
                                       keep='first')
```

### çµ±åˆIDã®ä»˜ä¸
```python
# åå¯„ã›å¾Œã®ãƒã‚¹ã‚¿ã‚’ä½œæˆ
integration_master = df_sorted[['customer_id', 'customer_name', 'postal_cd']] \
    .drop_duplicates(subset=['customer_name', 'postal_cd'], keep='first')
integration_master.columns = ['integration_id', 'customer_name', 'postal_cd']

# å…ƒãƒ‡ãƒ¼ã‚¿ã«çµ±åˆIDã‚’ä»˜ä¸
df_with_id = pd.merge(
    df, 
    integration_master[['integration_id', 'customer_name', 'postal_cd']], 
    on=['customer_name', 'postal_cd'], 
    how='left'
)
```

**ğŸ’¡ è€ƒãˆæ–¹**:
1. é‡è¤‡ã®åŸºæº–ï¼ˆåå‰+éƒµä¾¿ç•ªå·ãªã©ï¼‰ã‚’æ±ºã‚ã‚‹
2. ä»£è¡¨ãƒ‡ãƒ¼ã‚¿ã®é¸æŠåŸºæº–ã‚’æ±ºã‚ã‚‹ï¼ˆæœ€æ–°ã€æœ€å¤§ãªã©ï¼‰
3. ã‚½ãƒ¼ãƒˆ â†’ drop_duplicates ã§å®Ÿç¾

---

## 20. æ©Ÿæ¢°å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™ ã€P-089ï½P-091ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²ã—ãŸã„
> - æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ã«åˆ†å‰²ã—ãŸã„ï¼ˆæœªæ¥ã®ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰
> - ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ©ãƒ³ã‚¹ã‚ˆãã—ãŸã„

### ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆæ³•ï¼ˆå­¦ç¿’:ãƒ†ã‚¹ãƒˆ = 8:2 åˆ†å‰²ï¼‰
```python
from sklearn.model_selection import train_test_split

X = df[features]
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,      # 20%ã‚’ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«
    random_state=42,    # å†ç¾æ€§ã®ãŸã‚
    stratify=y          # ç›®çš„å¤‰æ•°ã®æ¯”ç‡ã‚’ä¿æŒï¼ˆä»»æ„ï¼‰
)
```

### æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆTime Series Splitï¼‰
æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€Œæœªæ¥ã®ãƒ‡ãƒ¼ã‚¿ã§éå»ã‚’äºˆæ¸¬ã—ãªã„ã€ã‚ˆã†ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
```python
from sklearn.model_selection import TimeSeriesSplit

# æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆã—ã¦ãŠãã“ã¨
df_sorted = df.sort_values('date')

tscv = TimeSeriesSplit(n_splits=3)

for train_index, test_index in tscv.split(df_sorted):
    df_train = df_sorted.iloc[train_index]  # éå»ã®ãƒ‡ãƒ¼ã‚¿
    df_test = df_sorted.iloc[test_index]    # æœªæ¥ã®ãƒ‡ãƒ¼ã‚¿
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»è©•ä¾¡
```

### ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
```python
from imblearn.under_sampling import RandomUnderSampler

X = df[features]
y = df['target']

rus = RandomUnderSampler(sampling_strategy={0: 1000, 1: 1000}, random_state=42)
X_resampled, y_resampled = rus.fit_resample(X, y)
```

**ğŸ’¡ è€ƒãˆæ–¹**:
- é€šå¸¸ãƒ‡ãƒ¼ã‚¿ â†’ ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆæ³•
- æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ â†’ TimeSeriesSplitï¼ˆæœªæ¥ã‚’è¦‹ãªã„ã‚ˆã†ã«åˆ†å‰²ï¼‰
- ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ â†’ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

---

## 21. æ­£è¦åŒ–ãƒ»éæ­£è¦åŒ–ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆï¼‰ ã€P-092ï½P-093ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆ†å‰²ã—ã¦ãƒã‚¹ã‚¿ã‚’ä½œã‚ŠãŸã„ï¼ˆæ­£è¦åŒ–ï¼‰
> - çµåˆã—ã¦1ã¤ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¾ã¨ã‚ãŸã„ï¼ˆéæ­£è¦åŒ–ï¼‰
> - é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã‚’æ’é™¤ã—ã¦ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚’åŠ¹ç‡åŒ–ã—ãŸã„

### ç¬¬ä¸‰æ­£è¦å½¢ã¸ã®æ­£è¦åŒ–
```python
# ã‚«ãƒ†ã‚´ãƒªãƒã‚¹ã‚¿ã‚’æŠ½å‡ºï¼ˆé‡è¤‡å‰Šé™¤ï¼‰
df_category_master = df[['category_major_cd', 'category_major_name', 
                          'category_medium_cd', 'category_medium_name',
                          'category_small_cd', 'category_small_name']] \
    .drop_duplicates()

# å•†å“ãƒã‚¹ã‚¿ï¼ˆã‚«ãƒ†ã‚´ãƒªåã‚’é™¤å¤–ï¼‰
df_product_master = df.drop(columns=['category_major_name', 
                                      'category_medium_name',
                                      'category_small_name'])
```

### éæ­£è¦åŒ–ï¼ˆã‚«ãƒ†ã‚´ãƒªåã®çµåˆï¼‰
```python
# å•†å“ãƒã‚¹ã‚¿ã«ã‚«ãƒ†ã‚´ãƒªåã‚’çµåˆ
df_denormalized = pd.merge(df_product, df_category, 
                           on=['category_major_cd', 'category_medium_cd', 'category_small_cd'],
                           how='left')
```

**ğŸ’¡ è€ƒãˆæ–¹**:
- æ­£è¦åŒ– â†’ ãƒ‡ãƒ¼ã‚¿ã®é‡è¤‡ã‚’æ’é™¤ï¼ˆæ›´æ–°ç•°å¸¸ã‚’é˜²ãï¼‰
- éæ­£è¦åŒ– â†’ èª­ã¿å–ã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Š

---

## 22. ãƒ•ã‚¡ã‚¤ãƒ«å…¥å‡ºåŠ› ã€P-094ï½P-100ã€‘

> **ğŸ’¬ ã“ã‚“ãªã¨ãã«ä½¿ã†**
> - DataFrameã‚’CSV/TSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ãŸã„
> - CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ãŸã„
> - æ–‡å­—åŒ–ã‘ã‚’é˜²ããŸã„ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æŒ‡å®šï¼‰

### CSVå‡ºåŠ›
```python
# UTF-8ã€ãƒ˜ãƒƒãƒ€ã‚ã‚Šã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—
df.to_csv('output.csv', encoding='utf-8', index=False)

# UTF-8 BOMä»˜ãï¼ˆExcelã§æ–‡å­—åŒ–ã‘é˜²æ­¢ï¼‰
df.to_csv('output.csv', encoding='utf-8-sig', index=False)

# CP932ï¼ˆShift-JISã€Windowsæ—¥æœ¬èªç’°å¢ƒï¼‰
df.to_csv('output.csv', encoding='cp932', index=False)

# ãƒ˜ãƒƒãƒ€ãªã—
df.to_csv('output.csv', encoding='utf-8', header=False, index=False)
```

### CSVèª­ã¿è¾¼ã¿
```python
# ãƒ˜ãƒƒãƒ€ã‚ã‚Š
df = pd.read_csv('input.csv', encoding='utf-8')

# ãƒ˜ãƒƒãƒ€ãªã—ï¼ˆåˆ—åã‚’æ‰‹å‹•æŒ‡å®šï¼‰
df = pd.read_csv('input.csv', encoding='utf-8', header=None,
                 names=['col1', 'col2', 'col3'])

# ãƒ‡ãƒ¼ã‚¿å‹ã‚’æŒ‡å®š
dtype_dict = {'customer_id': str, 'amount': int}
df = pd.read_csv('input.csv', encoding='utf-8', dtype=dtype_dict)
```

### TSVï¼ˆã‚¿ãƒ–åŒºåˆ‡ã‚Šï¼‰
```python
# TSVå‡ºåŠ›
df.to_csv('output.tsv', sep='\t', encoding='utf-8', index=False)

# TSVèª­ã¿è¾¼ã¿
df = pd.read_csv('output.tsv', sep='\t', encoding='utf-8')
# ã¾ãŸã¯
df = pd.read_table('output.tsv', encoding='utf-8')
```

### ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¸€è¦§
| ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° | ç”¨é€” | å‚™è€ƒ |
|------------------|------|------|
| `utf-8` | æ¨™æº–ï¼ˆæ±ç”¨ï¼‰ | Pythonã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ |
| `utf-8-sig` | Excelå¯¾å¿œï¼ˆBOMä»˜ãï¼‰ | æ—¥æœ¬èªExcelã§æ–‡å­—åŒ–ã‘é˜²æ­¢ |
| `cp932` | Windowsæ—¥æœ¬èª | Shift-JISã®æ‹¡å¼µ |
| `shift-jis` | æ—¥æœ¬èªï¼ˆæ—§å½¢å¼ï¼‰ | ä¸€éƒ¨æ–‡å­—ãŒæ‰±ãˆãªã„ã“ã¨ã‚‚ |

**ğŸ’¡ è€ƒãˆæ–¹**:
- Pythonå†…éƒ¨ â†’ UTF-8
- Excelé€£æº â†’ UTF-8 BOMä»˜ã
- Windowsæ—¥æœ¬èªç’°å¢ƒ â†’ CP932

---

## ğŸ“‹ å­¦ç¿’æ¨å¥¨é †åº

### ğŸ”° åˆç´šï¼ˆP-001ï½P-026, P-063ï½P-068, P-094ï½P-100ï¼‰
ãƒ‡ãƒ¼ã‚¿æ“ä½œã®åŸºç¤ã€ç®—è¡“æ¼”ç®—ã€ãƒ•ã‚¡ã‚¤ãƒ«I/O

### ğŸ¯ ä¸­ç´šï¼ˆP-027ï½P-062, P-075ï½P-083, P-092ï½P-093ï¼‰
çµ±è¨ˆåˆ†æã€çµåˆã€æ—¥ä»˜æ“ä½œã€ã‚«ãƒ†ã‚´ãƒªåŒ–ã€æ­£è¦åŒ–ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€æ¬ æå€¤å‡¦ç†

### ğŸš€ ä¸Šç´šï¼ˆP-041ï½P-044, P-069ï½P-074, P-084ï½P-091ï¼‰
ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°ã€è¤‡é›‘ãªé›†è¨ˆã€åœ°ç†ç©ºé–“ãƒ‡ãƒ¼ã‚¿ã€ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã€MLå‰å‡¦ç†

---

## ğŸ“ å•é¡Œã‚’è§£ãéš›ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹

### 1. è¦ä»¶ã®ç†è§£
- ä½•ã‚’å‡ºåŠ›ã™ã‚‹ã®ã‹ï¼Ÿ
- ã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†ã®ã‹ï¼Ÿ
- ã©ã‚“ãªæ¡ä»¶ãŒã‚ã‚‹ã®ã‹ï¼Ÿ

### 2. æ®µéšçš„ã«åˆ†è§£
- ä¸€åº¦ã«ã‚„ã‚ã†ã¨ã—ãªã„
- å°ã•ãªã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†ã‘ã‚‹
- ä¸­é–“çµæœã‚’ç¢ºèªã™ã‚‹

### 3. ä½¿ã†æŠ€è¡“ã®é¸å®š
- æ¡ä»¶æŠ½å‡º â†’ `query()`
- é›†è¨ˆ â†’ `groupby()`
- çµåˆ â†’ `merge()`
- å¤‰æ› â†’ `apply()`, `map()`

### 4. æ¬ æå€¤ã®è€ƒæ…®
- çµåˆå¾Œã«æ¬ æã¯ç™ºç”Ÿã—ãªã„ã‹ï¼Ÿ
- æ¬ æã‚’ã©ã†æ‰±ã†ã‹ï¼Ÿï¼ˆå‰Šé™¤ or è£œå®Œ or 0åŸ‹ã‚ï¼‰

### 5. ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèª
- æ–‡å­—åˆ—ã¨ã—ã¦æ‰±ã†ã¹ãã‹ï¼Ÿ
- æ•°å€¤ã¨ã—ã¦æ‰±ã†ã¹ãã‹ï¼Ÿ
- æ—¥ä»˜å‹ã«å¤‰æ›ã™ã¹ãã‹ï¼Ÿ

---

## ğŸ› ï¸ ã‚ˆãä½¿ã†ãƒ‘ã‚¿ãƒ¼ãƒ³é›†

### ãƒ‘ã‚¿ãƒ¼ãƒ³1: æ¡ä»¶æŠ½å‡º â†’ åˆ—é¸æŠ â†’ è¡¨ç¤º
```python
df.query('amount >= 1000')[['customer_id', 'amount']].head(10)
```

### ãƒ‘ã‚¿ãƒ¼ãƒ³2: é›†è¨ˆ â†’ ã‚½ãƒ¼ãƒˆ â†’ ä¸Šä½è¡¨ç¤º
```python
df.groupby('store_cd')['amount'].sum().sort_values(ascending=False).head(5)
```

### ãƒ‘ã‚¿ãƒ¼ãƒ³3: é›†è¨ˆ â†’ çµåˆ â†’ æ¯”ç‡è¨ˆç®—
```python
# å…¨ä½“ã®åˆè¨ˆã‚’è¨ˆç®—
df_total = df.groupby('id')['amount'].sum().reset_index()
df_total.columns = ['id', 'total_amount']  # åˆ—åã‚’å¤‰æ›´

# å…ƒãƒ‡ãƒ¼ã‚¿ã«çµåˆã—ã¦æ¯”ç‡ã‚’è¨ˆç®—
df_with_ratio = pd.merge(df, df_total, on='id')
df_with_ratio['ratio'] = df_with_ratio['amount'] / df_with_ratio['total_amount']
```

### ãƒ‘ã‚¿ãƒ¼ãƒ³4: ã‚°ãƒ«ãƒ¼ãƒ—åŒ– â†’ è¤‡æ•°é›†è¨ˆ â†’ åˆ—åå¤‰æ›´
```python
df_agg = df.groupby('id').agg({'date': ['max', 'min']}).reset_index()
df_agg.columns = ['id', 'max_date', 'min_date']
```

### ãƒ‘ã‚¿ãƒ¼ãƒ³5: æ—¥ä»˜å¤‰æ› â†’ ãƒ•ã‚£ãƒ«ã‚¿ â†’ é›†è¨ˆ
```python
df['date'] = pd.to_datetime(df['date_str'], format='%Y%m%d')
df_filtered = df.query('date >= "2019-01-01" and date < "2020-01-01"')
result = df_filtered.groupby('customer_id')['amount'].sum()
```

---

## ğŸ” ãƒ‡ãƒãƒƒã‚°ã®ã‚³ãƒ„

1. **ä¸­é–“çµæœã‚’ç¢ºèª**
   ```python
   df_tmp = df.groupby('col')['amount'].sum()
   print(df_tmp.head())  # ã“ã“ã§ç¢ºèª
   ```

2. **ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºèª**
   ```python
   print(df.dtypes)
   print(df['col'].dtype)
   ```

3. **æ¬ æå€¤ã‚’ç¢ºèª**
   ```python
   print(df.isnull().sum())
   ```

4. **ä»¶æ•°ã‚’ç¢ºèª**
   ```python
   print(len(df))
   print(df['col'].nunique())
   ```

5. **ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§è©¦ã™**
   ```python
   df.head(100).query('æ¡ä»¶')  # å…¨ãƒ‡ãƒ¼ã‚¿ã§ãªãä¸€éƒ¨ã§è©¦ã™
   ```

---

**æ›´æ–°æ—¥**: 2026å¹´2æœˆ2æ—¥  
**å¯¾è±¡ç¯„å›²**: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹100æœ¬ãƒãƒƒã‚¯ P-001ï½P-100  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: v1.0